# ğŸŒŸ JS Based Personal LLM ğŸŒŸ

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Repository Cloning 
1. Open your terminal or command prompt  ğŸ–¥ï¸
2. Clone the repository using the following command ğŸ”— 
   ```bash
   git clone https://github.com/vishangl/OpenTalkJS.git
3. Now enter into the clone file by using command ğŸ“‚
   ```bash
   cd OpenTalkJS
4. Now open the editor âœï¸
5. Write the script in the script.js file  ğŸ“
   ```bash
   import ollama from "ollama";

   async function runChat() 
   {
   try 
   {
    const response = await ollama.chat({
      model: "llama3.2:1b",
      messages: [{ role: 'user', content: "capital of UK" }]
    });

    console.log("Chatbot Response:", response.message.content);
    } 
    catch (error) 
    {
        console.error("Error occurred:", error.message);
    }
   }

   runChat();

### 2ï¸âƒ£ Dependencies installation
1. Check the version for the node using the command ğŸ› ï¸
   ```bash
   node -v
2. Now install ollam model ğŸ“¦
   ```bash
   npm install ollama
3. Check the version of the ollama ğŸ”
   ```bash
   ollama --version

### 3ï¸âƒ£ Application execution
1. Run the application using the command ğŸš¦
   ```bash 
   node script.js
2. View the Output ğŸ‰
   Your personal LLM will respond to your query about the capital of the UK!


